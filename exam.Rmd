---
title: "A cinema case study"
author: "Jodie Bregant"
output:
  ioslides_presentation:
    css: "./styles/style.css"
    incremental: yes
    widescreen: true    
    logo: "./images/film-solid.svg"
editor_options: 
  chunk_output_type: inline
---

```{r setup, echo = FALSE}

knitr::opts_chunk$set(cache = FALSE, message = FALSE, warning = FALSE)

```

# L' argomento

## Perchè?

> "No one cares about movies anymore. No one goes to cinema, no one really watches network TV. Everyone is watching Netflix." </br> 
**Ricky Gervais**

-   I tempi sono davvero cambiati e il cinema con essi?
-   Blockbuster. Sono davvero bei film o solo incredibilmente popolari?

> "Once Upon a Time in Hollywood, nearly three hours long. Leonardo DiCaprio attended the premiere, and by the end, his date was too old for him." </br> **Ricky Gervais**

-   Le persone sono infastidite dai film (troppo) lunghi?

```{r import, echo = FALSE}

# Importing libraries

library(readr)
library(dplyr)
library(tidyr)
library(qdapTools)
library(ggplot2)
library(ggExtra)
library(jsonlite)
library(rvest)
library(plotly)

# Disabling scientific notation

options(scipen = 999)

# Importing dataset from csv file

movies = read.csv("./datasets/movies.csv", stringsAsFactors = FALSE)

```

# I dati

## Dataset

### [IMDB Movies Dataset](https://www.kaggle.com/datasets/harshitshankhdhar/imdb-dataset-of-top-1000-movies-and-tv-shows)

<hr>

Il dataset contiene parecchi dati descrittivi su ciascuno dei film:

-   Titolo
-   Anno di rilascio (1920 - 2020)
-   Lunghezza (minuti)
-   Voto su IMDB
-   Ricavi
-   Genere / i


```{r tidy, include = FALSE}

# Renaming an ambiguous column and removing those we won't need

movies = movies %>% 
  rename_at('Series_Title', ~'Movie_Title') %>%
  select(-one_of(c("Poster_Link", "Certificate", "Overview", "Meta_score", "Director", "Star1", "Star2", "Star3", "Star4", "No_of_Votes")))

# Let's make sure no entries have duplicated primary keys (movie title)

movies = subset(movies, !duplicated(movies$Movie_Title))

# Removing row because it's not a film but a theatrical representation

movies = subset(movies, Movie_Title != "Hamilton")

# Let's convert non numeric values into numeric ones (where it makes sense to do so)

sapply(movies, class)

movies$Released_Year = as.numeric(movies$Released_Year)

movies$Runtime = gsub('[min]', '', movies$Runtime)
movies$Runtime = as.numeric(movies$Runtime)

movies$Gross = gsub('[,]', '', movies$Gross)
movies$Gross = as.numeric(movies$Gross)

# Checking for NA, NaN, Infinite and empty values

sapply(movies, function(x) sum(is.na(x)))

# A lot of NAs in gross

# Let's add that Released_Year missing since it's just one NA record

movies$Released_Year[movies$Movie_Title == "Apollo 13"] = 1995

sapply(movies, function(x) sum(is.nan(x)))
sapply(movies, function(x) sum(x == "Inf"))
sapply(movies, function(x) sum(x == ""))

# We need to turn categorical values in numeric ones -> one hot encoding
# Wouldn't make sense to just assign 1, 2, 3 to genres -> why is drama 3 times as genre as western?

# Not good when there are a lot of unique values though

# Since our Genre entries are composed by comma-separated values, we need to split them, one-hot encode them, and remove the original column since we won't need it anymore

movies = cbind(movies, mtabulate(strsplit(movies$Genre, ", ")))

movies = movies %>% 
  select(-one_of(c("Genre")))

```

```{r fetchmg, eval = FALSE, echo = FALSE}

# All these computations led to finalData -> saved on disk and then loaded

# Movies with no gross

movieNames = movies[is.na(movies$Gross), ]$Movie_Title
moviesIds = data.frame(title = character(), id = character(), stringsAsFactors = FALSE)

# Pasting URL in IMDB's search bar

for (movieName in movieNames) {
  url = paste0("https://www.imdb.com/find/?q=", URLencode(movieName), "&s=tt&exact=true")
  
  # Get HTML from URL
  
  webpage = read_html(url)
  
  # Extract the script node with id="__NEXT_DATA__"
  
  scriptNode = html_nodes(webpage, xpath = '//*[@id="__NEXT_DATA__"]')
  
  # Check if the script node exists
  
  if (length(scriptNode) > 0) {
    
    # Parse the content of the script node to JSON
    
    jsonContent = html_text(scriptNode) %>%
      jsonlite::parse_json()
    
    movieId = jsonContent$props$pageProps$titleResults$results[[1]]$id
    moviesIds = rbind(moviesIds, data.frame(title = movieName, id = movieId, stringsAsFactors = FALSE))
  }
}

# We got our movies' ID's, now we need grosses

finalData = data.frame(title = character(), gross = character(), stringsAsFactors = FALSE)

# From ID to Gross

for (i in 1:nrow(moviesIds)) {
  
  # URL to movie page with newly found id
  
  movieId = moviesIds$id[i]
  url = paste0("https://www.imdb.com/title/", movieId)
  
  # Get webpage html
  
  webpage = read_html(url)
  
  # Extract the script node with id "__NEXT_DATA__" and parse its content to JSON
  
  scriptNode = html_node(webpage, xpath = '//script[@id="__NEXT_DATA__"]')
  scriptContent = html_text(scriptNode)
  jsonContent = jsonlite::parse_json(scriptContent)
  
  # If gross is found, add to our final dataframe
  
  if (!is.null(jsonContent[["props"]][["pageProps"]][["mainColumnData"]][["worldwideGross"]])) {
    finalData = rbind(finalData, data.frame(title = moviesIds$title[i], 
                                             gross = jsonContent[["props"]][["pageProps"]][["mainColumnData"]][["worldwideGross"]][["total"]][["amount"]], 
                                             stringsAsFactors = FALSE))
  } else {
    finalData = rbind(finalData, data.frame(title = moviesIds$title[i], 
                                             gross = NA,
                                             stringsAsFactors = FALSE))
  }
}

save(finalData, file = "./saves/finalData.Rdata")

```

```{r loadmg, echo = FALSE}

# Let's fill the initial dataset with our newly obtained grosses and let's remove still NA's values (38)

load(file = "./saves/finalData.Rdata")

finalData$gross = as.numeric(finalData$gross)

fillGross = function(x) {
  finalData$gross[finalData$title == x]
}

movies$Gross[is.na(movies$Gross)] = sapply(movies$Movie_Title[is.na(movies$Gross)], fillGross)
movies = subset(movies, !is.na(movies$Gross))

```

# Generi

## Distribuzione {.build}

Prima di addentrarci in aspetti più approfonditi dei dati, andiamo a caratterizzare il dataset a livello di distribuzione dei generi.

```{r genresdist, echo = FALSE, fig.align = 'center'}

# Since we one-hot encoded them, we just need to sum all the cols without the need to count

genreCounts = data.frame(genre = colnames(movies[6:26]), count = sapply(movies[6:26], function(x) sum(x)))

ggplot(genreCounts, aes(x = reorder(genre, -count), y = count, fill = genre)) + 
  ggtitle("Distribution of genres") +
  geom_bar(stat = "identity") + scale_x_discrete(name = "Genre") +
  scale_y_continuous(name = "Number of movies", breaks = seq(0, 800, 100)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.7), legend.position = "none")

```

Incontriamo già una situazione interessante. </br>

Chiara prevalenza del genere drammatico </br>
La commedia è il secondo genere con più film </br>

# Il cinema nel tempo

## Ricavi

Andiamo ad esplorare l'andamento dei ricavi medi (dei film) all'anno, non prima di reperire i dati mancanti.

```{r wrongg, echo = FALSE, fig.align = 'center'}

# Grouped data

grossPerYearWrong = movies %>%
 group_by(Released_Year) %>%
 summarise_at(vars(Gross), list(meanGross = mean), na.rm = TRUE)

ggplot(grossPerYearWrong, aes(x = Released_Year, y = meanGross)) +
  ggtitle("Distribution of gross over time") +
  geom_line() +
  geom_smooth() +
  scale_x_continuous(name = "Released year", breaks = seq(1920, 2020, 10)) +
  scale_y_continuous(name = "Gross ($)") +
  theme_bw()

```

<br>

Sorprendentemente, ci troviamo di fronte ad un andamento strettamente crescente, con i minimi guadagni che si piazzano tra il 1920 e il 1950. Perchè? </br>

- Siamo a cavallo tra "Silent Years" e "Sound Era" (1920 - 1940) </br>
- Ma... </p> Sono anche gli anni in cui nascono quelli che diventeranno i grandi colossi cinematografici (Paramount, MGM, Fox) </br>

<hr>

- Gli stessi materiali che servivano per la celluloide erano necessari per la polvere da sparo (Prima Guerra Mondiale) </br>
- Ma... </p> il cinema americano ne ha beneficiato tantissimo, ed ha avuto un periodo di crescita, prosperità senza precedenti </br>

<br>

**Come è possibile che negli anni di Charlie Chaplin, di "Via Col Vento", di "Quarto Potere" i guadagni non si avvicino neanche lontanamente alla media degli anni successivi?**

## Ipotesi: distribuzione dei dati {.build}

```{r moviesdist data, echo = FALSE, fig.align = 'center'}

ggplot(data = movies) +
  ggtitle("Distribution of movies by released year") + 
  geom_bar(mapping = aes(x = Released_Year, fill = 1), width = 0.8) + 
  scale_x_continuous(name = "Released year", breaks = seq(1920, 2020, 10)) +
  scale_y_continuous(name = "Number of movies") + 
  theme_bw() + 
  theme(legend.position = "none")

```

Effettivamente, come possiamo notare, abbiamo molti più dati (logicamente) negli anni più recenti rispetto al periodo fino al 1960, bisogna quindi considerare che, utilizzando le medie, quelle calcolate su meno dati saranno molto più sensibili alle variazioni. </br> </br>

Controllando però di che dati fossimo forniti...

`r movies[movies$Movie_Title == "Gone with the Wind", c("Movie_Title", "Released_Year", "Gross")]` </br> `r movies[movies$Movie_Title == "Toy Story", c("Movie_Title", "Released_Year", "Gross")]` </br>

**Toy Story con praticamente gli stessi ricavi di Via col Vento?**

<h3> Inflazione. </h3>

## Ricavi considerando l'inflazione

```{r adjinflation, echo = FALSE}

# We need to adjust gross by inflation

# Checkpoint - dataset without inflation correction (movies) and with (moviesC)

moviesC = movies
years = sort(unique(moviesC$Released_Year))

# CPI - cumulative price increases (in percentages) from 1920 to 2020, sorted

CPI = c(1420.64, 1599.03, 1710.28, 1637.87, 1618.23, 1647.86, 1678.52, 1721.12, 1900.84, 2119.91, 2239.44, 2169.60, 2119.91, 2087.96, 2011.99,
  2056.93, 2087.96, 2072.34, 1968.89, 1765.81, 1657.96, 1627.99, 1589.59, 1459.63, 1263.80, 1161.94, 1177.84, 1161.94, 1069.72, 1047.65, 1039.05, 1030.58, 
  1034.80, 1018.11, 982.30, 952.34, 945.11, 927.46, 917.15, 907.04, 893.88, 881.05, 865.48, 838.66, 810.56, 773.93, 728.68, 683.83, 650.93, 627.58, 584.97, 
  516.89, 465.29, 434.49, 401.86, 366.45, 318.91, 269.09, 234.57, 215.16, 205.35, 192.71, 182.65, 177.49, 167.72, 157.08, 145.26, 132.69, 123.29, 116.77, 
  110.47, 105.21, 99.56, 93.83, 89.49, 86.58, 82.55, 76.61, 71.73, 69.05, 65.29, 61.00, 55.72, 50.86, 46.68, 41.26, 41.76, 39.47, 35.20, 32.46, 30.55, 28.47, 
  28.31, 26.72, 24.07, 21.06, 18.96, 17.51, 16.02)

priceIncrease = setNames(CPI, as.list(years))

# Updating grosses

adjGross = function(x) {
  f = moviesC[moviesC$Movie_Title == x, ]
  gross = f$Gross
  year = f$Released_Year
  
  if(!is.na(gross)) {
    gross = ((gross / 100) * priceIncrease[as.character(year)]) + gross
  } else {
    gross = NA
  }
}

# Replacing grosses

newPrices = sapply(moviesC$Movie_Title, adjGross)
moviesC$Gross = as.array(newPrices)

```

<center>

```{r grossvstime, echo = FALSE, fig.align = 'center'}

# Grouped data

grossPerYear = moviesC %>%
  group_by(Released_Year) %>%
  summarise_at(vars(Gross), list(meanGross = mean), na.rm = TRUE)

ggplotly(ggplot(grossPerYear, aes(x = Released_Year, y = meanGross)) + 
  ggtitle("Distribution of gross over time", "Considering inflation") + 
  geom_line() + 
  geom_smooth() + 
  scale_x_continuous(name = "Released year", breaks = seq(1920, 2020, 10)) + 
  scale_y_continuous(name = "Gross ($)") + 
  theme_bw())

# Raw data

# ggplot(moviesC, aes(x = Released_Year, y = Gross)) +
#   ggtitle("Distribution of gross over time", "Considering inflation") +
#   geom_point() +
#   scale_x_continuous(name = "Released year", breaks = seq(1920, 2020, 10)) +
#   scale_y_continuous(name = "Gross ($, log)", trans = "log") +
#   theme_bw()

```

</center> </br>

L'andamento è ora drasticamente cambiato, e vediamo come ora ci siano delle spike in corrispondenza del 1933 ("The Invisible Man"), del 1939 ("Gone with the Wind").

Possiamo inoltre notare come i film tra il 1960 e il 1980 abbiamo avuto, in generale, più successo.

## Rating

Vediamo ora le valutazioni medie dei film negli anni.

<center>

```{r ratingvstime, echo = FALSE, fig.align = 'center'}

# Visualizing mean rating per year

# Grouped data

ratingPerYear = moviesC %>%
  group_by(Released_Year) %>%
  summarise_at(vars(IMDB_Rating), list(meanRating = mean))

ggplotly(ggplot(ratingPerYear, aes(x = Released_Year, y = meanRating)) + 
  ggtitle("Distribution of rating over time") + 
  geom_line() + 
  geom_smooth() + 
  scale_x_continuous(name = "Released year", breaks = seq(1920, 2020, 10)) + 
  scale_y_continuous(name = "Rating") + 
  theme_bw())

# Raw data
# 
# ggplot(moviesC, aes(x = Released_Year, y = IMDB_Rating)) +
#   ggtitle("Distribution of rating over time") +
#   geom_point() +
#   scale_x_continuous(name = "Released year", breaks = seq(1920, 2020, 10)) +
#   scale_y_continuous(name = "Rating") +
#   theme_bw()

```

</center> </br>

Sorprendentemente, l'andamento delle valutazioni medie dei film per anno è caratterizzata da un trend descrescente. </br> Inoltre:

-   Molta più variabilità fino agli anni '60
-   Andamento più piatto dopo i 2000

## Allora? {.build}

A questo punto, concludiamo che </br>

*Sì, i tempi sono cambiati* </br>

Il cinema sembra aver avuto il suo picco di popolarità tra gli anni '60 e '80, e non sembra aver vissuto da allora momenti altrettanto proficui. </br> Inoltre, le persone giudicano i film più vecchi migliori di quelli recenti, che sembrano aver perso di qualità (in base alle votazioni ricevute)

# Blockbusters vs capolavori

## Ricavo e votazione {.build}

Andiamo a scoprire come si comportano i ricavi in relazione con le votazioni ricevute dai film.

```{r grossvsratingraw, echo = FALSE, fig.align = 'center'}

# Raw data

ggplot(moviesC, aes(x = IMDB_Rating, y = Gross)) +
  ggtitle("Distribution of gross over rating") +
  geom_point(alpha = 0.3) +
  scale_x_continuous(name = "IMDB Rating") +
  scale_y_continuous(name = "Gross ($, log)", trans = "log") +
  theme_bw()

```

La distribuzione dei dati fa pensare ad una correlazione: semplifichiamo il grafico in modo da vederla meglio.

```{r grossvsrating, echo = FALSE, fig.align = 'center'}

# Grouped data

# Correlation between gross and rating?

grossPerRating = moviesC %>%
  group_by(IMDB_Rating) %>%
  summarise_at(vars(Gross), list(meanGross = mean)) %>%
  as.data.frame()


# ggplot(grossPerRating, aes(x = IMDB_Rating, y = meanGross)) + 
#   ggtitle("Distribution of gross over rating") + 
#   geom_point() + 
#   scale_x_continuous(name = "IMDB Rating") + 
#   scale_y_continuous(name = "Gross") + 
#   theme_bw()

```

<center>

```{r firstreg, echo = FALSE, fig.align = 'center'}

# Looks like an exponential regression could do okay

# m = lm(meanGross ~ exp(IMDB_Rating), grossPerRating)
# summary(m)
# cor(grossPerRating$meanGross, exp(grossPerRating$IMDB_Rating))

ggplotly(ggplot(grossPerRating, aes(x = IMDB_Rating, y = meanGross)) +
  geom_point() +
  scale_x_continuous(name = "IMDB Rating") +
  scale_y_continuous(name = "Gross ($)") +
  geom_smooth(method = "lm", formula = y ~ exp(x)) +
  theme_bw())

```

</center> </br>

Come possiamo vedere, la zona grigia che si riferisce al 'confidence interval' è abbastanza ampia: la correlazione non è fortissima. </br> Perchè? </br> Possiamo notare un 'outlier' che sta grandemente influenzando l'analisi.

```{r secondreg, echo = FALSE, fig.align = 'center'}

# As we can see the last point at the far right is clearly an outlier -> very high rating but 'low' gross.
# Since we are considering means and there's only one movie in the dataset with that rating, that is affecting our analysis.

# Let's try to fit the model without the outlier

grossPerRating = subset(grossPerRating, grossPerRating$IMDB_Rating != 9.3)

# m = lm(meanGross ~ exp(IMDB_Rating), grossPerRating)
# summary(m)
# cor(grossPerRating$meanGross, exp(grossPerRating$IMDB_Rating))

# ggplot(grossPerRating, aes(x = IMDB_Rating, y = meanGross)) + 
#   ggtitle("Distribution of gross over rating") + 
#   geom_point() + 
#   scale_x_continuous(name = "IMDB Rating") + 
#   scale_y_continuous(name = "Gross") + 
#   geom_smooth(method = "lm", formula = y ~ exp(x)) + 
#   theme_bw()


# Clearly better

```

```{r polyfit, echo = FALSE, fig.align = 'center'}

# Let's replace exponential regression with polynomial regression

# K-fold cross validation to find best degree of the poly to use, avoiding over and underfitting

# Shuffling data

gppShuf = grossPerRating[sample(nrow(grossPerRating)), ]

# Number of folds to use - usually 5 or 10

K = 5

# Degrees of the poly to test

degrees = 5

# Splitting dataset in K = 5 equal folds

folds = cut(seq(1, nrow(gppShuf)), breaks = K, labels = FALSE)

mse = matrix(data = NA, nrow = K, ncol = degrees)

for(i in 1:K){
    
    # Splitting training and testing data
  
    testIndexes = which(folds == i, arr.ind = TRUE)
    testData = gppShuf[testIndexes, ]
    trainData = gppShuf[-testIndexes, ]
    
    # Evaluation
    
    for (j in 1:degrees){
        fitTrain = lm(meanGross ~ poly(IMDB_Rating, j), data = trainData)
        fitTest = predict(fitTrain, newdata = testData)
        mse[i, j] = mean((fitTest - testData$meanGross) ^ 2) 
    }
}

# MSE for each degree

# colMeans(mse)

# Lowest MSE is poly degree 2, which is our best fit

```

```{r polyreg data, echo = FALSE, fig.align = 'center'}

# m = lm(meanGross ~ poly(IMDB_Rating, 2), grossPerRating)
# summary(m)
# cor(grossPerRating$meanGross, poly(grossPerRating$IMDB_Rating, 2))

ggplot(grossPerRating, aes(x = IMDB_Rating, y = meanGross)) +
  ggtitle("Distribution of gross over rating") +
  geom_point() +
  scale_x_continuous(name = "IMDB Rating") +
  scale_y_continuous(name = "Gross ($)") +
  geom_smooth(method = "lm", formula = y ~ poly(x, 2)) +
  theme_bw()

# Clearly better (again)

```

Abbiamo la nostra correlazione: in genere, più alto è il voto ricevuto dal film, più esso andrà bene al *box-office*. </br>

Inaspettato: di solito, quindi, la qualità di un film viene premiata a livello di guadagni.

# Soglia di attenzione

## Lunghezza del film e votazioni {.build}

Visualizziamo ora come si piazzano le votazioni quando comparati con la lunghezza del film.

```{r ratingvsruntimeraw, echo = FALSE, fig.align = 'center'}

# Raw data

# ggMarginal(ggplot(movies, aes(x = Runtime, y = IMDB_Rating)) +
#              ggtitle("Distribution of rating over runtime") +
#              geom_point(alpha = 0.3) +
#              scale_x_continuous(name = "Runtime") +
#              scale_y_continuous(name = "Rating") +
#              theme_bw(), type = "boxplot")

```

```{r ratingvsruntime, echo = FALSE, fig.align = 'center'}

# Grouped data

ratingPerRuntime = moviesC %>%
  group_by(Runtime) %>%
  summarise_at(vars(IMDB_Rating), list(meanRating = mean))

ggplot(ratingPerRuntime, aes(x = Runtime, y = meanRating)) + 
             ggtitle("Distribution of rating over runtime") + 
             geom_point() + scale_x_continuous(name = "Runtime (min)", breaks = seq(0, 350, 50)) + 
             scale_y_continuous(name = "Rating") + 
             theme_bw()

# summary(lm(meanRating ~ Runtime, ratingPerRuntime))
# cor(ratingPerRuntime$Runtime, ratingPerRuntime$meanRating)

# No clear correlation
 
```

Vediamo come la maggior parte dei film si aggiri sui 120 minuti, e le votazioni intorno all'8. </br> Per come sono disposti i dati, non sembra esserci correlazione significativa. </br>
Sorprendente.

## Lunghezza del film e ricavi

Verifichiamo se il *runtime* influisce invece sui ricavi

```{r grossvsruntime, echo = FALSE, fig.align = 'center'}

# Grouped data

# grossPerRuntime = moviesC %>%
#   group_by(Runtime) %>%
#   summarise_at(vars(Gross), list(meanGross = mean))
# 
# ggplot(grossPerRuntime, aes(x = Runtime, y = meanGross)) +
#   ggtitle("Distribution of gross over runtime") +
#   geom_point() +
#   scale_x_continuous(name = "Runtime") +
#   scale_y_continuous(name = "Gross ($, log)", trans = "log") +
#   theme_bw()

# Raw data

# Using a log scale otherwise gross would be smashed against x-axis

ggplot(moviesC, aes(x = Runtime, y = Gross)) +
  ggtitle("Distribution of gross over runtime") +
  geom_point(alpha = 0.45) +
  scale_x_continuous(name = "Runtime (min)") +
  scale_y_continuous(name = "Gross ($, log)", trans = "log") +
  theme_bw()

```

Il grafico ci mostra dove troviamo la maggior parte di film: intorno ai 130 minuti e al miliardo di incassi. </br> Ancora una volta l'analisi ci smentisce, evidentemente la lunghezza del film non è un fattore che influenza incasso o votazione.

## Concludendo

1. I tempi sono davvero cambiati e il cinema con essi? </br>
Sì. Il cinema ha avuto il suo picco di popolarità tra gli anni '60 e '80, a livello di ricavi. </br>
Le persone ritengono, in media, migliori i film più vecchi rispetto a quelli più recenti.

2. Blockbuster. Sono davvero bei film o solo incredibilmente popolari? </br>
"Blockbuster" sembra coincidere con "bel film": una pellicola con votazioni alte solitamente ha anche incassi elevati.

3. Le persone sono infastidite dai film (troppo) lunghi? </br>
No. La lunghezza di un film non sembra essere un fattore che incide sulla valutazione o sul ricavo dello stesso. </br>

# Fin.
